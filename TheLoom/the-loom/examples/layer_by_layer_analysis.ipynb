{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Layer-by-Layer Hidden State Analysis Tutorial\n",
    "\n",
    "This notebook demonstrates how to use **The Loom** for layer-by-layer hidden state extraction and analysis.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Extracting hidden states from specific layers** (e.g., `[-1, -5, -11]`)\n",
    "2. **Computing D_eff (effective dimensionality)** per layer\n",
    "3. **Visualizing D_eff evolution** across transformer layers\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- The Loom server running (`docker run -d --gpus all -p 8080:8080 tbucy/loom:latest`)\n",
    "- Python packages: `numpy`, `matplotlib`, `httpx`\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "**D_eff (Effective Dimensionality)** measures the intrinsic dimensionality of embedding space:\n",
    "\n",
    "- Computed via PCA eigenvalue analysis\n",
    "- Returns the number of dimensions needed to capture 90% of variance\n",
    "- Lower D_eff = more compressed representations\n",
    "- Higher D_eff = richer, more diverse representations\n",
    "\n",
    "*Reference: Whiteley et al. \"Statistical exploration of the Manifold Hypothesis\" (arXiv:2208.11665)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory for The Loom imports\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.client import LoomClient\n",
    "from src.analysis.conveyance_metrics import calculate_d_eff, calculate_d_eff_detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LOOM_URL = \"http://localhost:8080\"\n",
    "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "PROMPT = \"The fundamental nature of reality is\"\n",
    "\n",
    "# Layers to analyze\n",
    "# Negative indices: -1 = last, -5 = 5th from last, -11 = 11th from last\n",
    "TARGETED_LAYERS = [-1, -5, -11]\n",
    "\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Prompt: '{PROMPT}'\")\n",
    "print(f\"Target Layers: {TARGETED_LAYERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to The Loom server\n",
    "client = LoomClient(base_url=LOOM_URL)\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    health = client.health()\n",
    "    print(f\"Connected to The Loom!\")\n",
    "    print(f\"Server Status: {health.get('status', 'unknown')}\")\n",
    "    print(f\"GPU Available: {health.get('gpu', {}).get('available', False)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting: {e}\")\n",
    "    print(\"\\nMake sure The Loom is running:\")\n",
    "    print(\"  docker run -d --gpus all -p 8080:8080 tbucy/loom:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction-section",
   "metadata": {},
   "source": [
    "## 2. Extracting Hidden States from Specific Layers\n",
    "\n",
    "The Loom allows you to specify exactly which layers you want hidden states from using the `hidden_state_layers` parameter.\n",
    "\n",
    "**Layer indexing:**\n",
    "- `-1` = Last layer (final semantic representation)\n",
    "- `-5` = 5th layer from the end\n",
    "- `\"all\"` = Every layer in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-targeted",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states from specific layers: [-1, -5, -11]\n",
    "result = client.generate(\n",
    "    model=MODEL_ID,\n",
    "    prompt=PROMPT,\n",
    "    max_tokens=20,\n",
    "    return_hidden_states=True,\n",
    "    hidden_state_layers=TARGETED_LAYERS,\n",
    ")\n",
    "\n",
    "print(f\"Generated text: '{result['text']}'\")\n",
    "print(f\"Token count: {result['token_count']}\")\n",
    "print(f\"\\nHidden states returned for layers: {list(result['hidden_states'].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "examine-layers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the hidden states\n",
    "for layer_key, layer_data in result['hidden_states'].items():\n",
    "    print(f\"\\nLayer {layer_key}:\")\n",
    "    print(f\"  Shape: {layer_data['shape']}\")\n",
    "    print(f\"  Dtype: {layer_data['dtype']}\")\n",
    "    \n",
    "    # Quick stats on the hidden state vector\n",
    "    data = np.array(layer_data['data'])\n",
    "    print(f\"  Mean: {data.mean():.4f}\")\n",
    "    print(f\"  Std: {data.std():.4f}\")\n",
    "    print(f\"  L2 Norm: {np.linalg.norm(data):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff-section",
   "metadata": {},
   "source": [
    "## 3. Computing D_eff (Effective Dimensionality) Per Layer\n",
    "\n",
    "D_eff tells us how many dimensions are \"active\" in a hidden state representation.\n",
    "\n",
    "For a single hidden state vector, we estimate D_eff by analyzing the contribution of each dimension to the total magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_d_eff_single_vector(vector: np.ndarray, variance_threshold: float = 0.90) -> int:\n",
    "    \"\"\"Compute D_eff for a single hidden state vector.\n",
    "    \n",
    "    For a single vector, we estimate D_eff by treating each dimension\n",
    "    as a sample and computing how many are needed to capture 90% of\n",
    "    the total magnitude.\n",
    "    \n",
    "    Parameters:\n",
    "        vector: The hidden state vector (1D numpy array)\n",
    "        variance_threshold: Target cumulative contribution (default 0.90)\n",
    "    \n",
    "    Returns:\n",
    "        Estimated effective dimensionality\n",
    "    \"\"\"\n",
    "    # Flatten if needed\n",
    "    vector = vector.flatten()\n",
    "    \n",
    "    # Sort by absolute value (descending)\n",
    "    abs_values = np.abs(vector)\n",
    "    sorted_vals = np.sort(abs_values)[::-1]\n",
    "    \n",
    "    # Compute cumulative contribution\n",
    "    total = sorted_vals.sum()\n",
    "    if total == 0:\n",
    "        return 1\n",
    "    \n",
    "    cumsum = np.cumsum(sorted_vals) / total\n",
    "    d_eff = int(np.searchsorted(cumsum, variance_threshold) + 1)\n",
    "    \n",
    "    return min(d_eff, len(vector))\n",
    "\n",
    "# Test on the last layer\n",
    "last_layer = result['hidden_states']['-1']\n",
    "vector = np.array(last_layer['data'])\n",
    "d_eff = compute_d_eff_single_vector(vector)\n",
    "\n",
    "print(f\"Layer -1 Analysis:\")\n",
    "print(f\"  Hidden Size: {len(vector)}\")\n",
    "print(f\"  D_eff (90%): {d_eff}\")\n",
    "print(f\"  Utilization: {d_eff / len(vector):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff-all-targeted",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute D_eff for all targeted layers\n",
    "layer_analysis = {}\n",
    "\n",
    "for layer_key, layer_data in result['hidden_states'].items():\n",
    "    vector = np.array(layer_data['data'])\n",
    "    d_eff = compute_d_eff_single_vector(vector)\n",
    "    hidden_size = layer_data['shape'][-1]\n",
    "    \n",
    "    layer_analysis[int(layer_key)] = {\n",
    "        'layer': int(layer_key),\n",
    "        'd_eff': d_eff,\n",
    "        'hidden_size': hidden_size,\n",
    "        'utilization': d_eff / hidden_size,\n",
    "        'l2_norm': float(np.linalg.norm(vector)),\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "print(\"\\nD_eff Analysis for Targeted Layers:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Layer':>8} {'D_eff':>8} {'Hidden':>8} {'Util.':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for layer_idx in sorted(layer_analysis.keys()):\n",
    "    info = layer_analysis[layer_idx]\n",
    "    print(f\"{info['layer']:>8} {info['d_eff']:>8} {info['hidden_size']:>8} {info['utilization']:>10.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "all-layers-section",
   "metadata": {},
   "source": [
    "## 4. Full Layer Analysis (All Layers)\n",
    "\n",
    "Now let's analyze **all layers** to see how D_eff evolves through the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hidden states from ALL layers\n",
    "# When hidden_state_layers is not specified, the server returns all layers\n",
    "full_result = client.generate(\n",
    "    model=MODEL_ID,\n",
    "    prompt=PROMPT,\n",
    "    max_tokens=20,\n",
    "    return_hidden_states=True,\n",
    "    # Not specifying hidden_state_layers returns all layers\n",
    ")\n",
    "\n",
    "all_hidden_states = full_result.get('hidden_states', {})\n",
    "print(f\"Number of layers returned: {len(all_hidden_states)}\")\n",
    "print(f\"Layer keys: {sorted(all_hidden_states.keys(), key=int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute D_eff for all layers\n",
    "full_analysis = {}\n",
    "\n",
    "for layer_key, layer_data in all_hidden_states.items():\n",
    "    vector = np.array(layer_data['data'])\n",
    "    d_eff = compute_d_eff_single_vector(vector)\n",
    "    hidden_size = layer_data['shape'][-1]\n",
    "    \n",
    "    full_analysis[int(layer_key)] = {\n",
    "        'layer': int(layer_key),\n",
    "        'd_eff': d_eff,\n",
    "        'hidden_size': hidden_size,\n",
    "        'utilization': d_eff / hidden_size,\n",
    "        'mean': float(np.mean(vector)),\n",
    "        'std': float(np.std(vector)),\n",
    "        'l2_norm': float(np.linalg.norm(vector)),\n",
    "    }\n",
    "\n",
    "# Display summary\n",
    "layers_sorted = sorted(full_analysis.keys())\n",
    "d_effs = [full_analysis[l]['d_eff'] for l in layers_sorted]\n",
    "\n",
    "print(f\"\\nFull Layer Analysis Summary:\")\n",
    "print(f\"  Total Layers: {len(full_analysis)}\")\n",
    "print(f\"  Mean D_eff: {np.mean(d_effs):.1f}\")\n",
    "print(f\"  Std D_eff: {np.std(d_effs):.1f}\")\n",
    "print(f\"  Min D_eff: {np.min(d_effs)} (Layer {layers_sorted[np.argmin(d_effs)]})\")\n",
    "print(f\"  Max D_eff: {np.max(d_effs)} (Layer {layers_sorted[np.argmax(d_effs)]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-section",
   "metadata": {},
   "source": [
    "## 5. Plotting D_eff Across Layers\n",
    "\n",
    "Visualization helps us understand how information is transformed through the network:\n",
    "\n",
    "- **Early layers**: Often process raw features (higher D_eff)\n",
    "- **Middle layers**: Abstraction and compression\n",
    "- **Final layers**: Task-specific representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "layers = [full_analysis[l]['layer'] for l in layers_sorted]\n",
    "d_effs = [full_analysis[l]['d_eff'] for l in layers_sorted]\n",
    "utilization = [full_analysis[l]['utilization'] for l in layers_sorted]\n",
    "hidden_size = full_analysis[layers_sorted[0]]['hidden_size']\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Absolute D_eff values\n",
    "ax1.plot(layers, d_effs, 'b-o', linewidth=2, markersize=6)\n",
    "ax1.axhline(y=hidden_size, color='r', linestyle='--', alpha=0.5,\n",
    "            label=f'Hidden Size ({hidden_size})')\n",
    "ax1.set_xlabel('Layer Index', fontsize=12)\n",
    "ax1.set_ylabel('D_eff (Effective Dimensionality)', fontsize=12)\n",
    "ax1.set_title(f'D_eff by Layer - {MODEL_ID}', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: D_eff as fraction of hidden size\n",
    "colors = ['red' if u < 0.3 else 'orange' if u < 0.6 else 'green' for u in utilization]\n",
    "ax2.bar(layers, utilization, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=0.9, color='g', linestyle='--', alpha=0.5, label='90% Threshold')\n",
    "ax2.axhline(y=0.3, color='r', linestyle='--', alpha=0.5, label='30% Threshold')\n",
    "ax2.set_xlabel('Layer Index', fontsize=12)\n",
    "ax2.set_ylabel('D_eff / Hidden Size', fontsize=12)\n",
    "ax2.set_title('Dimensional Utilization by Layer', fontsize=14)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('layer_deff_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: layer_deff_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-section",
   "metadata": {},
   "source": [
    "## 6. D_eff Trajectory Analysis\n",
    "\n",
    "Let's analyze how D_eff changes between consecutive layers to identify:\n",
    "- **Compression points** (D_eff decreases)\n",
    "- **Expansion points** (D_eff increases)\n",
    "- **Bottleneck layers** (significant compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trajectory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute layer-to-layer changes\n",
    "changes = []\n",
    "for i in range(1, len(layers_sorted)):\n",
    "    prev_layer = layers_sorted[i-1]\n",
    "    curr_layer = layers_sorted[i]\n",
    "    \n",
    "    prev_deff = full_analysis[prev_layer]['d_eff']\n",
    "    curr_deff = full_analysis[curr_layer]['d_eff']\n",
    "    \n",
    "    change = curr_deff - prev_deff\n",
    "    pct_change = (change / prev_deff * 100) if prev_deff > 0 else 0\n",
    "    \n",
    "    changes.append({\n",
    "        'from_layer': prev_layer,\n",
    "        'to_layer': curr_layer,\n",
    "        'change': change,\n",
    "        'pct_change': pct_change,\n",
    "    })\n",
    "\n",
    "# Identify significant changes (>10% compression or expansion)\n",
    "print(\"\\nSignificant D_eff Changes Between Layers:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'From':>8} -> {'To':>8}  {'Change':>10} {'Percent':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for c in changes:\n",
    "    if abs(c['pct_change']) > 10:\n",
    "        direction = \"compression\" if c['change'] < 0 else \"expansion\"\n",
    "        print(f\"{c['from_layer']:>8} -> {c['to_layer']:>8}  {c['change']:>+10}  {c['pct_change']:>+9.1f}% ({direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "change-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the changes\n",
    "change_values = [c['change'] for c in changes]\n",
    "layer_pairs = [f\"{c['from_layer']}â†’{c['to_layer']}\" for c in changes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "colors = ['red' if v < 0 else 'green' for v in change_values]\n",
    "ax.bar(range(len(change_values)), change_values, color=colors, alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel('Layer Transition', fontsize=12)\n",
    "ax.set_ylabel('D_eff Change', fontsize=12)\n",
    "ax.set_title('D_eff Changes Between Consecutive Layers', fontsize=14)\n",
    "ax.set_xticks(range(0, len(layer_pairs), 2))\n",
    "ax.set_xticklabels([layer_pairs[i] for i in range(0, len(layer_pairs), 2)], rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "compressions = sum(1 for c in changes if c['change'] < 0)\n",
    "expansions = sum(1 for c in changes if c['change'] > 0)\n",
    "print(f\"\\nSummary: {compressions} compression steps, {expansions} expansion steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpretation-section",
   "metadata": {},
   "source": [
    "## 7. Interpretation Guide\n",
    "\n",
    "### Understanding D_eff\n",
    "\n",
    "**D_eff (Effective Dimensionality)** measures how many dimensions are actively used in a hidden state representation:\n",
    "\n",
    "| D_eff / Hidden_Size | Interpretation |\n",
    "|---------------------|----------------|\n",
    "| > 0.7 | High utilization - rich, diverse representations |\n",
    "| 0.3 - 0.7 | Moderate - typical for most layers |\n",
    "| < 0.3 | Low utilization - compressed or collapsed |\n",
    "\n",
    "### Typical Patterns\n",
    "\n",
    "1. **Early layers**: Often higher D_eff (processing raw input features)\n",
    "2. **Middle layers**: Variable - abstraction forming\n",
    "3. **Final layers**: Often task-specific (may show compression)\n",
    "\n",
    "### Research Applications\n",
    "\n",
    "- **Bottleneck detection**: Find layers where D_eff drops significantly\n",
    "- **Model comparison**: Compare D_eff trajectories across models\n",
    "- **Feature extraction**: Identify optimal layers for downstream tasks\n",
    "- **Alignment research**: Study how representations evolve with different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "client.close()\n",
    "print(\"\\nAnalysis complete! Client connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Multi-agent comparison**: Compare D_eff patterns across different models\n",
    "2. **Prompt sensitivity**: Analyze how D_eff changes with different prompts\n",
    "3. **Full sequence analysis**: Use `return_full_sequence=True` for manifold analysis\n",
    "4. **Beta calculation**: Compute collapse indicators using `calculate_beta()`\n",
    "\n",
    "See the `src/analysis/conveyance_metrics.py` module for advanced metrics:\n",
    "- `calculate_d_eff_detailed()` - Full eigenvalue analysis\n",
    "- `calculate_beta()` - Collapse indicator\n",
    "- `calculate_c_pair()` - Pairwise conveyance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
